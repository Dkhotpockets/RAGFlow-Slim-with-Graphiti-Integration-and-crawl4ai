version: '3.8'
services:
  ragflow-server:
    build: .
    container_name: ragflow-server
    ports:
      - "5000:5000"
    depends_on:
      - ragflow-mysql
      - ragflow-redis
      - ragflow-minio
      - ragflow-es-01
      - ragflow-neo4j
    volumes:
      - ./outputs:/app/outputs
      - ./docker/entrypoint.sh:/ragflow/entrypoint.sh
    environment:
      - FLASK_ENV=production
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_KEY=${SUPABASE_KEY}
      - NEO4J_URI=bolt://ragflow-neo4j:7687
      - NEO4J_USER=${NEO4J_USER:-neo4j}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      # Multi-Provider LLM Configuration
      - LLM_PROVIDER=${LLM_PROVIDER:-google}
      # Google Gemini (PRIMARY for entity extraction via Graphiti)
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - GOOGLE_MODEL=${GOOGLE_MODEL:-gemini-2.5-flash}
      # Ollama (for embeddings - http://host.docker.internal:11434)
      - OLLAMA_HOST=http://host.docker.internal:11434
      - OLLAMA_MODEL=qwen2.5-coder:3b
      - OLLAMA_EMBED_MODEL=nomic-embed-text
      # Crawl4AI Configuration
      - CRAWL4AI_ENABLED=true
      - CRAWL4AI_MAX_CONCURRENT_JOBS=5
      - CRAWL4AI_JOB_TIMEOUT_SECONDS=300
      - CRAWL4AI_MAX_RETRIES=3
      - CRAWL4AI_DEFAULT_MAX_DEPTH=1
      - CRAWL4AI_DEFAULT_TIMEOUT_SECONDS=30
      - CRAWL4AI_DEFAULT_MAX_CONTENT_SIZE=5242880
      - CRAWL4AI_DEFAULT_RESPECT_ROBOTS=true
      - CRAWL4AI_DEFAULT_FOLLOW_REDIRECTS=true
      - CRAWL4AI_DEFAULT_EXTRACT_METADATA=true
      - CRAWL4AI_USER_AGENT=RAGFlow-Crawler/1.0
      - CRAWL4AI_MIN_CONTENT_LENGTH=100
      - CRAWL4AI_MAX_CONTENT_LENGTH=10485760
      - CRAWL4AI_SUPPORTED_CONTENT_TYPES=text/html,application/xhtml+xml,text/plain
      - CRAWL4AI_RATE_LIMIT_PER_MINUTE=60
      - CRAWL4AI_RATE_LIMIT_BURST=10
      # Security
      - RAGFLOW_API_KEY=${RAGFLOW_API_KEY}
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS:-http://localhost:3000}
    extra_hosts:
      - "host.docker.internal:host-gateway"  # For accessing host Ollama on Linux
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:5000/health').raise_for_status()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped

  ragflow-mysql:
    image: mysql:8.0.39
    container_name: ragflow-mysql
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ragflow
      MYSQL_USER: ragflow
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
    ports:
      - "3306:3306"
    volumes:
      - ./docker/init.sql:/data/application/init.sql

  ragflow-redis:
    image: valkey/valkey:8
    container_name: ragflow-redis
    restart: unless-stopped
    ports:
      - "6379:6379"

  ragflow-minio:
    image: quay.io/minio/minio:RELEASE.2025-06-13T11-33-47Z
    container_name: ragflow-minio
    restart: unless-stopped
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    ports:
      - "9000:9000"
      - "9001:9001"
    command: server /data --console-address ":9001"

  ragflow-es-01:
    image: elasticsearch:8.11.3
    container_name: ragflow-es-01
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - xpack.security.enabled=false
    mem_limit: 1g
    ports:
      - "9200:9200"
      - "9300:9300"

  ragflow-neo4j:
    image: neo4j:5.18.0
    container_name: ragflow-neo4j
    restart: unless-stopped
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD}
      - NEO4J_PLUGINS=["apoc", "graph-data-science"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*,gds.*
      - NEO4J_dbms_memory_heap_max__size=2G
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    volumes:
      - neo4j-data:/data
      - neo4j-logs:/logs

volumes:
  neo4j-data:
  neo4j-logs:
